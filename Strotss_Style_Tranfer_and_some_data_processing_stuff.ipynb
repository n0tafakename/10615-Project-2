{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Strotss Style Tranfer and some data processing stuff",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This code is mostly a modification of the STROTSS handout provided by Peter Schaldenbrand. Modifications include processing of local images, generation of masks from training images, and applying those masks to the style transfer output"
      ],
      "metadata": {
        "id": "N2gXku7r1djP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STROTSS Style Transfer Notebook\n",
        "\n",
        "#### [Style Transfer by Relaxed Optimal Transport and Self-Similarity (STROTSS)](https://arxiv.org/abs/1904.12785)\n",
        "\n",
        "Code from: https://github.com/futscdav/strotss\n",
        "\n",
        "Notebook by: Peter Schaldenbrand"
      ],
      "metadata": {
        "id": "zIQqTo4quiwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JihukNAZk7bJ"
      },
      "outputs": [],
      "source": [
        "#@title Download the strotss code from GitHub\n",
        "\n",
        "import os\n",
        "if not os.path.exists('/content/strotss'):\n",
        "    !git clone https://github.com/futscdav/strotss.git\n",
        "os.chdir('/content/strotss')\n",
        "from strotss import *\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount drive for convenient file access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "bU47XQZfac-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Copy and unzip training data\n",
        "os.chdir('/')\n",
        "!cp \"/content/gdrive/MyDrive/10615/STROTSS Starry Night Chair/*\" /content/\n",
        "!unzip /content/chair_train.zip\n",
        "!unzip /content/chair_styled.zip\n",
        "!unzip /content/chair_styled_sharp.zip\n"
      ],
      "metadata": {
        "id": "bckYNRxLsAiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Helper Functions\n",
        "import torch\n",
        "import requests\n",
        "import PIL.Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import adjust_sharpness\n",
        "import glob\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if not torch.cuda.is_available():\n",
        "    print('YOU ARE NOT USING A GPU.  IT\\'S GONNA BE REAAALLLLY SLOW')\n",
        "    print('Go to the top of the page.  Click Runtime -> Change Runtime Type -> Hardware accelerator')\n",
        "    print('From the dropdown, select GPU and rerun all this stuff')\n",
        "\n",
        "def pil_loader_internet(url):\n",
        "    response = requests.get(url)\n",
        "    img = PIL.Image.open(BytesIO(response.content))\n",
        "    return img.convert('RGB')\n",
        "\n",
        "def pil_loader_local(path, sharpness=1, encoding=\"RGB\"):\n",
        "    with open(path, \"rb\") as f:\n",
        "        img = PIL.Image.open(BytesIO(f.read()))\n",
        "        if sharpness == 1:\n",
        "            return img.convert(encoding)\n",
        "        else:\n",
        "            return adjust_sharpness(img.convert(encoding), sharpness)\n",
        "\n",
        "def show_img(img):\n",
        "    # Code for displaying at actual resolution from:\n",
        "    # https://stackoverflow.com/questions/28816046/displaying-different-images-with-actual-size-in-matplotlib-subplot\n",
        "    dpi = 80\n",
        "    height, width, depth = img.shape\n",
        "    figsize = width / float(dpi), height / float(dpi)\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_style_and_content(style, content):\n",
        "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
        "    ax[0].imshow(content)\n",
        "    ax[0].set_xticks([])\n",
        "    ax[0].set_yticks([])\n",
        "    ax[0].set_title('Content')\n",
        "    ax[1].imshow(style)\n",
        "    ax[1].set_xticks([])\n",
        "    ax[1].set_yticks([])\n",
        "    ax[1].set_title('Style')\n",
        "    plt.show()\n",
        "\n",
        "# takes an image and creates a binary mask, must be RGBA format\n",
        "def image_to_mask(img):\n",
        "    img_arr = pil_to_np(img)\n",
        "    for r in range(img_arr.shape[0]):\n",
        "        for c in range(img_arr.shape[1]):\n",
        "            if not np.all(img_arr[r, c] == 0):\n",
        "                img_arr[r, c, :] = (255, 255, 255, 255)\n",
        "    \n",
        "    return np_to_pil(img_arr)\n",
        "\n",
        "# Applies mask to an image, must be RGBA format\n",
        "def mask_image(img, mask):\n",
        "    img_arr = pil_to_np(img)\n",
        "    mask_arr = pil_to_np(mask)\n",
        "\n",
        "    for r in range(img_arr.shape[0]):\n",
        "        for c in range(img_arr.shape[1]):\n",
        "            if np.all(mask_arr[r, c] == 0):\n",
        "                img_arr[r, c, :] = (0, 0, 0, 0)\n",
        "    \n",
        "    return np_to_pil(img_arr)"
      ],
      "metadata": {
        "id": "NmlZQJjzlNOx"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define STROTSS function\n",
        "# Redefine the STROTSS function to put some debugging statements in\n",
        "\n",
        "def strotss(content_pil, style_pil, content_weight=1.0*16.0, device='cuda:0', space='uniform'):\n",
        "    content_np = pil_to_np(content_pil)\n",
        "    style_np = pil_to_np(style_pil)\n",
        "    content_full = np_to_tensor(content_np, space).to(device)\n",
        "    style_full = np_to_tensor(style_np, space).to(device)\n",
        "\n",
        "    lr = 2e-3\n",
        "    extractor = Vgg16_Extractor(space=space).to(device)\n",
        "\n",
        "    scale_last = max(content_full.shape[2], content_full.shape[3])\n",
        "    scales = []\n",
        "    for scale in range(10):\n",
        "        divisor = 2**scale\n",
        "        if min(content_pil.width, content_pil.height) // divisor >= 33:\n",
        "            scales.insert(0, divisor)\n",
        "    \n",
        "    clow = -1.0 if space == 'uniform' else -1.7\n",
        "    chigh = 1.0 if space == 'uniform' else 1.7\n",
        "\n",
        "    for scale in scales:\n",
        "        # rescale content to current scale\n",
        "        content = tensor_resample(content_full, [ content_full.shape[2] // scale, content_full.shape[3] // scale ])\n",
        "        style = tensor_resample(style_full, [ style_full.shape[2] // scale, style_full.shape[3] // scale ])\n",
        "        print(f'Optimizing at resoluton [{content.shape[2]}, {content.shape[3]}]')\n",
        "\n",
        "        # upsample or initialize the result\n",
        "        if scale == scales[0]:\n",
        "            # first\n",
        "            result = laplacian(content) + style.mean(2,keepdim=True).mean(3,keepdim=True)\n",
        "        elif scale == scales[-1]:\n",
        "            # last \n",
        "            result = tensor_resample(result, [content.shape[2], content.shape[3]])\n",
        "            lr = 1e-3\n",
        "        else:\n",
        "            result = tensor_resample(result, [content.shape[2], content.shape[3]]) + laplacian(content)\n",
        "\n",
        "        # do the optimization on this scale\n",
        "        result = optimize(result, content, style, scale, content_weight=content_weight, lr=lr, extractor=extractor)\n",
        "\n",
        "        # Show intermediate result\n",
        "        result_image = tensor_to_np(torch.clamp(result, clow, chigh)) # \n",
        "        # renormalize image\n",
        "        result_image -= result_image.min()\n",
        "        result_image /= result_image.max()\n",
        "        show_img(result_image)\n",
        "\n",
        "        # next scale lower weight\n",
        "        content_weight /= 2.0\n",
        "\n",
        "    result_image = tensor_to_np(tensor_resample(torch.clamp(result, clow, chigh), [content_full.shape[2], content_full.shape[3]])) # \n",
        "    # renormalize image\n",
        "    result_image -= result_image.min()\n",
        "    result_image /= result_image.max()\n",
        "    return np_to_pil(result_image * 255.)"
      ],
      "metadata": {
        "id": "GmLiAUYLorkm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the starry night image\n",
        "style_url = 'https://m.media-amazon.com/images/I/91iS91eizUL._AC_SL1500_.jpg'\n",
        "style_pil = pil_loader_internet(style_url)\n",
        "\n",
        "max_width = 512\n",
        "\n",
        "content_weight = 0.7\n",
        "content_weight *= 16.0 \n",
        "\n",
        "sharpness = 3\n",
        "\n",
        "for fname in glob.glob(\"/content/chair_train/*\"):\n",
        "    if os.path.exists(fname.replace(\"train\", \"styled\")):\n",
        "        # Incase colab kills instance before finishing\n",
        "        print(f\"Already have a styled {fname} computed\")\n",
        "        continue\n",
        "\n",
        "    content_pil = pil_loader_local(fname, sharpness)\n",
        "    result = strotss(pil_resize_long_edge_to(content_pil, max_width), \n",
        "            pil_resize_long_edge_to(style_pil, max_width), \n",
        "            content_weight, device, \"vgg\")\n",
        "    print('Final Result')\n",
        "    show_img(pil_to_np(result))\n",
        "    result.save(fname.replace(\"train\", \"styled\"), format=\"png\")\n",
        "    if sharpness != 1:\n",
        "        content_pil.save(fname.replace(\"train\", \"train_sharp\"), format=\"png\")\n"
      ],
      "metadata": {
        "id": "t5FK8vJhzsGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in glob.glob(\"/content/chair_train/*\"):\n",
        "    content_pil = pil_loader_local(fname, encoding=\"RGBA\")\n",
        "    content_pil = pil_resize_long_edge_to(content_pil, 512)\n",
        "    mask_pil = image_to_mask(content_pil)\n",
        "    mask_pil.save(fname.replace(\"train\", \"mask\"), format=\"png\")\n"
      ],
      "metadata": {
        "id": "k6zmg755qHkX"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in glob.glob(\"/content/chair_styled/*\"):\n",
        "    styled_content_pil = pil_loader_local(fname, encoding=\"RGBA\")\n",
        "    mask_pil = pil_loader_local(fname.replace(\"styled\", \"mask\"), encoding=\"RGBA\")\n",
        "    styled_masked_content_pil = mask_image(styled_content_pil, mask_pil)\n",
        "\n",
        "    styled_masked_content_pil.save(fname.replace(\"styled\", \"styled_maskedafter\"), format=\"png\")\n"
      ],
      "metadata": {
        "id": "Cmb1Iz5gxUqV"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/chair_styled_maskedafter.zip /content/chair_styled_maskedafter\n",
        "# !zip -r /content/chair_mask.zip /content/chair_mask"
      ],
      "metadata": {
        "id": "LhMfXwHo85lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/chair_styled_maskedafter.zip \"/content/gdrive/MyDrive/10615/STROTSS Starry Night Chair\"\n",
        "# !cp /content/chair_mask.zip  /content/gdrive/MyDrive/10615"
      ],
      "metadata": {
        "id": "nXRwob11atWe"
      },
      "execution_count": 92,
      "outputs": []
    }
  ]
}